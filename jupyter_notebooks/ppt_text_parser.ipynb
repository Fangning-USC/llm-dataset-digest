{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from country_named_entity_recognition import find_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_file = r\"\"\"C:\\Users\\fangning.zheng\\Documents\\weekly summary\\week05\\nlp-experiments-gists\\fangzhen\\langchain_streamlit_chatbot\\src\\langchain_streamlit_chatbot\\data_ppt\\4COffshore_MarketOverviewReport_2021_Q1.pptx\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_to_nonempty_table_cells(tbl: object, text_len_threshold: int) -> str:\n",
    "   \"\"\"\n",
    "   :param tbl: 'pptx.table.Table'\n",
    "\n",
    "   :return: return iterator to non-empty rows\n",
    "   \"\"\"\n",
    "   if len(tbl.rows) < 6 or len(tbl.columns) < 6:\n",
    "      for ridx in range(sum(1 for _ in iter(tbl.rows))):\n",
    "         for cidx in range(sum(1 for _ in iter(tbl.columns))):\n",
    "            cell = tbl.cell(ridx, cidx)\n",
    "            txt = type(\"\")(cell.text)\n",
    "            txt = txt.strip()\n",
    "            if txt:\n",
    "               # find if country name exists\n",
    "               txt_with_countries = find_countries(txt)\n",
    "               # get the font size (not robust)\n",
    "               text_frame = cell.text_frame\n",
    "               paragraph = text_frame.paragraphs[0]\n",
    "               for run in paragraph.runs:\n",
    "                  font = run.font\n",
    "                  try:\n",
    "                     # get font size (not robust)\n",
    "                     font_size = font.size.pt\n",
    "                  except:\n",
    "                     font_size = 0\n",
    "\n",
    "               if txt_with_countries:\n",
    "                  yield txt + '\\n'\n",
    "               elif (len(txt.split(\" \")) > text_len_threshold) and (font_size > 8):\n",
    "                  yield txt + '\\n'\n",
    "               elif txt[-1] in '.':\n",
    "                  yield txt + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_json(path: str, item: dict, item_name: str) -> None:\n",
    "    with open((\"\\\\\\\\?\\\\\" + path + \"\\\\\" + item_name), \"w\") as outfile:\n",
    "        json.dump(item, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx.enum.shapes import MSO_SHAPE_TYPE \n",
    "\n",
    "ppt_path = r\"\"\"C:\\Users\\fangning.zheng\\Documents\\weekly summary\\week05\\nlp-experiments-gists\\fangzhen\\langchain_streamlit_chatbot\\src\\langchain_streamlit_chatbot\\data_ppt\"\"\"\n",
    "\n",
    "files = [x for x in os.listdir(ppt_path) if x.endswith(\".pptx\")] \n",
    "\n",
    "# ungroup all the grouped shapes so that the parser can recognize the text frames within a group.\n",
    "for file in files:\n",
    "    presentation = Presentation(ppt_path + \"\\\\\" + file)\n",
    "    for slide in presentation.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.GROUP:\n",
    "                group = shape.element\n",
    "                parent = group.getparent()\n",
    "                index = parent.index(group)\n",
    "                for member in group:\n",
    "                    parent.insert(index, member)\n",
    "                    index += 1\n",
    "                parent.remove(group)\n",
    "    os.chdir(ppt_path)\n",
    "    presentation.save(\"ungroup_\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse and store text separately\n",
    "\n",
    "line_len_threshold = 4\n",
    "text_len_threshold = 4\n",
    "ppt_path = r\"\"\"C:\\Users\\fangning.zheng\\Documents\\weekly summary\\week05\\nlp-experiments-gists\\fangzhen\\langchain_streamlit_chatbot\\src\\langchain_streamlit_chatbot\\data_ppt\"\"\"\n",
    "\n",
    "files = [x for x in os.listdir(ppt_path) if x.endswith(\".pptx\")] \n",
    "\n",
    "for file in files:\n",
    "    file_name = str(file).split(\".\")[0]\n",
    "    folder_name = ppt_path + \"\\\\\" + file_name\n",
    "    \n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    prs = Presentation(ppt_path + \"\\\\\" + str(file))\n",
    "    output_file = \"\"\n",
    "\n",
    "    for i, slide in enumerate(prs.slides):\n",
    "        output_page = \"\"\n",
    "        if slide.shapes:\n",
    "            output_file += \"\\n\\n\" + \"---------- Page \" + str(i+1) + \"------------\" + \"\\n\"\n",
    "            \n",
    "            # sort the shapes by coord for each page\n",
    "            shapes_coord = []\n",
    "            for shape in slide.shapes:\n",
    "                # find the coordinates of shape\n",
    "                x = round(shape.left.inches,2)\n",
    "                y = round(shape.top.inches,2)\n",
    "                width = round(shape.width.inches,2)\n",
    "                height = round(shape.height.inches,2)\n",
    "                # append shape\n",
    "                shapes_coord.append((x, y, width, height, shape))\n",
    "            # sort the list of shapes\n",
    "            shapes_coord_sort = sorted(shapes_coord, key=lambda element: (element[0], element[1]))\n",
    "\n",
    "            item_counter = 1\n",
    "            for j, item in enumerate(shapes_coord_sort):\n",
    "                if i+1 < 10:\n",
    "                    item_name = \"pg\"+str(0)+str(i+1)+\"_text\"+str(item_counter)+\"_\"+file_name\n",
    "                else:\n",
    "                    item_name = \"pg\"+str(i+1)+\"_text\"+str(item_counter)+\"_\"+file_name\n",
    "                # create empty dict for each shape\n",
    "                dict_shape = {\"text\": \"\", \"text_type\":\"\", \"coordinates\": item[:4], \"doc_name\": file_name, \"doc_year\": re.match(r'.*([1-3][0-9]{3})', file_name).group(1), \"doc_quarter\": file_name[-1], \"page\": str(i+1)}\n",
    "\n",
    "                shape = item[4]\n",
    "                \n",
    "\n",
    "                # if the shape is a text frame with text\n",
    "                if hasattr(shape, \"text\") and len(str(shape.text).strip().split(\" \")) > 1:\n",
    "                    # get the text from the text frame\n",
    "                    shape_text = shape.text.strip() + \"\\n\"\n",
    "\n",
    "                    # get the font size (not robust)\n",
    "                    text_frame = shape.text_frame\n",
    "                    paragraph = text_frame.paragraphs[0]\n",
    "                    for run in paragraph.runs:\n",
    "                        font = run.font\n",
    "                        try:\n",
    "                            # get font size and bold check (not robust)\n",
    "                            font_size = font.size.pt\n",
    "                        except:\n",
    "                            font_size = 0\n",
    "\n",
    "                    # get the length of string for each line in the text frame\n",
    "                    shape_len = [(len(line.strip().split(\" \"))) for line in (shape_text.strip().split(\"\\n\"))]\n",
    "\n",
    "                    # if length is greater than threshold\n",
    "                    if (max(shape_len) > text_len_threshold) and (font_size > 8 or font_size == 0) and (shape_text not in output_file):\n",
    "                        output_page += \"---------\" + item_name + \"----------\\n\"\n",
    "                        output_page += shape_text\n",
    "\n",
    "                        dict_shape[\"text\"] = shape_text\n",
    "                        dict_shape[\"text_type\"] = \"text\"\n",
    "                        save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "                        item_counter += 1\n",
    "                        \n",
    "                    # if length not greater than threshold, check if the text is a title\n",
    "                    elif (font_size > 20 or font_size == 0) and shape_text not in output_file:\n",
    "                        output_page += \"---------\" + item_name + \"----------\\n\"\n",
    "                        output_page += shape_text\n",
    "\n",
    "                        dict_shape[\"text\"] = shape_text\n",
    "                        dict_shape[\"text_type\"] = \"title\"\n",
    "                        save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "                        item_counter += 1\n",
    "                    \n",
    "                    elif shape_text[-2] in '.':\n",
    "                        output_page += \"---------\" + item_name + \"----------\\n\"\n",
    "                        output_page += shape_text\n",
    "\n",
    "                        dict_shape[\"text\"] = shape_text\n",
    "                        dict_shape[\"text_type\"] = \"text\"\n",
    "                        save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "                        item_counter += 1\n",
    "\n",
    "                # for parsing table                \n",
    "                elif shape.has_table:\n",
    "                    tables_pg = list()\n",
    "                    tables = shape.table\n",
    "                    tables_pg.append(tables)\n",
    "                    for table in tables_pg:\n",
    "                        table_text_ = iter_to_nonempty_table_cells(table, text_len_threshold)\n",
    "                        table_text = \"\".join(table_text_)\n",
    "                    shape_len = [(len(line.strip().split(\" \"))) for line in (table_text.strip().split(\"\\n\"))]\n",
    "\n",
    "                    if (len(shape_len) > line_len_threshold or max(shape_len) > text_len_threshold) and table_text not in output_file:\n",
    "                        output_page += \"---------\" + item_name + \"----------\\n\"\n",
    "                        output_page += table_text\n",
    "                        \n",
    "\n",
    "                        dict_shape[\"text\"] = table_text\n",
    "                        dict_shape[\"text_type\"] = \"table\"\n",
    "                        save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "                        item_counter += 1\n",
    "\n",
    "                \n",
    "\n",
    "        #if len(output_page.strip().split(\" \")) > text_len_threshold:\n",
    "        output_file += output_page\n",
    "        os.chdir(ppt_path)\n",
    "        with open(file_name+\".txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "            text_file.write(str(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse and store text together within one page\n",
    "\n",
    "line_len_threshold = 4\n",
    "text_len_threshold = 4\n",
    "ppt_path = r\"\"\"C:\\Users\\fangning.zheng\\Documents\\weekly summary\\week05\\nlp-experiments-gists\\fangzhen\\langchain_streamlit_chatbot\\src\\langchain_streamlit_chatbot\\data_ppt\"\"\"\n",
    "\n",
    "files = [x for x in os.listdir(ppt_path) if x.endswith(\".pptx\")] \n",
    "\n",
    "for file in files:\n",
    "    file_name = str(file).split(\".\")[0]\n",
    "    folder_name = ppt_path + \"\\\\\" + file_name\n",
    "    \n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    prs = Presentation(ppt_path + \"\\\\\" + str(file))\n",
    "    output_file = \"\"\n",
    "\n",
    "    for i, slide in enumerate(prs.slides):\n",
    "        output_page = \"\"\n",
    "        output_text_page = \"\"\n",
    "\n",
    "        if slide.shapes:            \n",
    "            # sort the shapes by coord for each page\n",
    "            shapes_coord = []\n",
    "            for shape in slide.shapes:\n",
    "                # find the coordinates of shape\n",
    "                x = round(shape.left.inches,2)\n",
    "                y = round(shape.top.inches,2)\n",
    "                width = round(shape.width.inches,2)\n",
    "                height = round(shape.height.inches,2)\n",
    "                # append shape\n",
    "                shapes_coord.append((x, y, width, height, shape))\n",
    "            # sort the list of shapes\n",
    "            shapes_coord_sort = sorted(shapes_coord, key=lambda element: (element[0], element[1]))\n",
    "\n",
    "            # create empty dict for each shape\n",
    "            dict_shape = {\"text\": \"\", \"text_type\":\"\", \"doc_name\": file_name, \"doc_year\": re.match(r'.*([1-3][0-9]{3})', file_name).group(1), \"doc_quarter\": file_name[-1], \"page\": str(i+1)}\n",
    "\n",
    "            #item_counter = 1\n",
    "            for j, item in enumerate(shapes_coord_sort):\n",
    "                if i+1 < 10:\n",
    "                    # add a zero before numbering\n",
    "                    item_name = \"pg\"+str(0)+str(i+1)+\"_text\"+\"_\"+file_name\n",
    "                else:\n",
    "                    item_name = \"pg\"+str(i+1)+\"_text\"+\"_\"+file_name\n",
    "                shape = item[4]\n",
    "                \n",
    "                # if the shape is a text frame with text\n",
    "                if hasattr(shape, \"text\") and len(str(shape.text).strip().split(\" \")) > 1:\n",
    "                    # get the text from the text frame, and replace multiple newlines into one newline\n",
    "                    shape_text_ = re.sub(\"\\n+\", \"\\n\", shape.text.strip())\n",
    "                    shape_text = shape_text_ + \"\\n\" + \"\\n\"\n",
    "\n",
    "                    # get the font size (not robust)\n",
    "                    text_frame = shape.text_frame\n",
    "                    paragraph = text_frame.paragraphs[0]\n",
    "                    for run in paragraph.runs:\n",
    "                        font = run.font\n",
    "                        try:\n",
    "                            # get font size and bold check (not robust)\n",
    "                            font_size = font.size.pt\n",
    "                        except:\n",
    "                            font_size = 0\n",
    "\n",
    "                    # get the length of string for each line in the text frame\n",
    "                    shape_len = [(len(line.strip().split(\" \"))) for line in (shape_text.strip().split(\"\\n\"))]\n",
    "\n",
    "                    # if length is greater than threshold\n",
    "                    if (max(shape_len) > text_len_threshold) and (font_size > 8 or font_size == 0) and (shape_text not in output_file):\n",
    "                        output_page += shape_text\n",
    "                        output_text_page += shape_text\n",
    "\n",
    "                        \"\"\"dict_shape[\"text\"] = shape_text\n",
    "                        dict_shape[\"text_type\"] = \"text\"\"\"\n",
    "                        \"\"\"save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "                        item_counter += 1\"\"\"\n",
    "                        \n",
    "                    # if length not greater than threshold, check if the text is a title\n",
    "                    elif (font_size > 20 or font_size == 0) and shape_text not in output_file:\n",
    "                        output_page += shape_text\n",
    "                        output_text_page += shape_text\n",
    "\n",
    "                    \n",
    "                    elif shape_text[-2] in '.':\n",
    "                        output_page += shape_text\n",
    "                        output_text_page += shape_text\n",
    "\n",
    "                # for parsing table                \n",
    "                elif shape.has_table:\n",
    "                    tables_pg = list()\n",
    "                    tables = shape.table\n",
    "                    tables_pg.append(tables)\n",
    "                    for table in tables_pg:\n",
    "                        table_text_ = iter_to_nonempty_table_cells(table, text_len_threshold)\n",
    "                        table_text = \"\".join(table_text_)\n",
    "                    shape_len = [(len(line.strip().split(\" \"))) for line in (table_text.strip().split(\"\\n\"))]\n",
    "\n",
    "                    if (len(shape_len) > line_len_threshold or max(shape_len) > text_len_threshold) and table_text not in output_file:\n",
    "                        output_page += table_text\n",
    "                        output_text_page += table_text\n",
    "\n",
    "        if output_text_page.strip():\n",
    "            # store into json file\n",
    "            dict_shape[\"text\"] = output_text_page\n",
    "            dict_shape[\"text_type\"] = \"text\"\n",
    "            save_to_json(path=folder_name, item=dict_shape, item_name=item_name)\n",
    "            \n",
    "            output_file += \"\\n\\n\" + \"---------- Page \" + str(i+1) + \"------------\" + \"\\n\"\n",
    "            output_file += output_page\n",
    "            os.chdir(ppt_path)\n",
    "            with open(file_name+\".txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "                text_file.write(str(output_file))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
